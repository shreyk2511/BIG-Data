{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70dqFwcLPAGW",
        "outputId": "e87a6d6f-2a25-4664-e9c4-9fe3932e9cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 40 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 61.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=0c06f9b0241e1eae0a98e38abeb729ce700bfb359fda1c7aed2e841495f26b01\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "IHzA5PYGPHtJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('SparkWindowFunction').getOrCreate()"
      ],
      "metadata": {
        "id": "_D_IrgACPH5Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData = ((\"James\", \"Sales\", 3000), \\\n",
        "    (\"Madhav\", \"Sales\", 4600),  \\\n",
        "    (\"Rohit\", \"Sales\", 4100),   \\\n",
        "    (\"Mitesh\", \"Finance\", 3000),  \\\n",
        "    (\"Gursheen\", \"Sales\", 3000),    \\\n",
        "    (\"Yash\", \"Finance\", 3300),  \\\n",
        "    (\"Ben\", \"Finance\", 3900),    \\\n",
        "    (\"Pnadey\", \"Marketing\", 3000), \\\n",
        "    (\"Kumar\", \"Marketing\", 2000),\\\n",
        "    (\"Shah\", \"Sales\", 4100) \\\n",
        "  )"
      ],
      "metadata": {
        "id": "Bl4zmU1APIDL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns= [\"employee_name\", \"department\", \"salary\"]"
      ],
      "metadata": {
        "id": "3VHxJHDgPINS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data = simpleData, schema = columns)"
      ],
      "metadata": {
        "id": "uJgO8KRWPIVv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYV9GN65PIey",
        "outputId": "1c61ab2d-343e-4e7a-8330-cf21cec49a34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Madhav       |Sales     |4600  |\n",
            "|Rohit        |Sales     |4100  |\n",
            "|Mitesh       |Finance   |3000  |\n",
            "|Gursheen     |Sales     |3000  |\n",
            "|Yash         |Finance   |3300  |\n",
            "|Ben          |Finance   |3900  |\n",
            "|Pnadey       |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Shah         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number"
      ],
      "metadata": {
        "id": "R-KouYCpPVxb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n"
      ],
      "metadata": {
        "id": "56oO0ZQSPV6I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"row_number\",row_number().over(windowSpec)).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk5THsTFPWCe",
        "outputId": "35249928-5c21-4f08-9dc8-32df84167437"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|employee_name|department|salary|row_number|\n",
            "+-------------+----------+------+----------+\n",
            "|Mitesh       |Finance   |3000  |1         |\n",
            "|Yash         |Finance   |3300  |2         |\n",
            "|Ben          |Finance   |3900  |3         |\n",
            "|Kumar        |Marketing |2000  |1         |\n",
            "|Pnadey       |Marketing |3000  |2         |\n",
            "|James        |Sales     |3000  |1         |\n",
            "|Gursheen     |Sales     |3000  |2         |\n",
            "|Rohit        |Sales     |4100  |3         |\n",
            "|Shah         |Sales     |4100  |4         |\n",
            "|Madhav       |Sales     |4600  |5         |\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rank\n",
        "df.withColumn(\"rank\",rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItYIx0SpPWKJ",
        "outputId": "36ec8aac-5659-47bc-f996-925c44869ee4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|employee_name|department|salary|rank|\n",
            "+-------------+----------+------+----+\n",
            "|       Mitesh|   Finance|  3000|   1|\n",
            "|         Yash|   Finance|  3300|   2|\n",
            "|          Ben|   Finance|  3900|   3|\n",
            "|        Kumar| Marketing|  2000|   1|\n",
            "|       Pnadey| Marketing|  3000|   2|\n",
            "|        James|     Sales|  3000|   1|\n",
            "|     Gursheen|     Sales|  3000|   1|\n",
            "|        Rohit|     Sales|  4100|   3|\n",
            "|         Shah|     Sales|  4100|   3|\n",
            "|       Madhav|     Sales|  4600|   5|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import dense_rank\n",
        "df.withColumn(\"dense_rank\",dense_rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnXKR8HCPfR7",
        "outputId": "97394fbe-89fd-43cb-a732-e5b10e8e1b58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|employee_name|department|salary|dense_rank|\n",
            "+-------------+----------+------+----------+\n",
            "|       Mitesh|   Finance|  3000|         1|\n",
            "|         Yash|   Finance|  3300|         2|\n",
            "|          Ben|   Finance|  3900|         3|\n",
            "|        Kumar| Marketing|  2000|         1|\n",
            "|       Pnadey| Marketing|  3000|         2|\n",
            "|        James|     Sales|  3000|         1|\n",
            "|     Gursheen|     Sales|  3000|         1|\n",
            "|        Rohit|     Sales|  4100|         2|\n",
            "|         Shah|     Sales|  4100|         2|\n",
            "|       Madhav|     Sales|  4600|         3|\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import percent_rank\n",
        "df.withColumn(\"percent_rank\",percent_rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A_ntIW7PfY5",
        "outputId": "32fec7c5-efac-4b2f-ec00-306c6f81f1b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------------+\n",
            "|employee_name|department|salary|percent_rank|\n",
            "+-------------+----------+------+------------+\n",
            "|       Mitesh|   Finance|  3000|         0.0|\n",
            "|         Yash|   Finance|  3300|         0.5|\n",
            "|          Ben|   Finance|  3900|         1.0|\n",
            "|        Kumar| Marketing|  2000|         0.0|\n",
            "|       Pnadey| Marketing|  3000|         1.0|\n",
            "|        James|     Sales|  3000|         0.0|\n",
            "|     Gursheen|     Sales|  3000|         0.0|\n",
            "|        Rohit|     Sales|  4100|         0.5|\n",
            "|         Shah|     Sales|  4100|         0.5|\n",
            "|       Madhav|     Sales|  4600|         1.0|\n",
            "+-------------+----------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import ntile\n",
        "df.withColumn(\"ntile\",ntile(2).over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96nQ3njDPfhA",
        "outputId": "9d037888-dfd6-4675-bc7a-0d5c49b7c034"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-----+\n",
            "|employee_name|department|salary|ntile|\n",
            "+-------------+----------+------+-----+\n",
            "|       Mitesh|   Finance|  3000|    1|\n",
            "|         Yash|   Finance|  3300|    1|\n",
            "|          Ben|   Finance|  3900|    2|\n",
            "|        Kumar| Marketing|  2000|    1|\n",
            "|       Pnadey| Marketing|  3000|    2|\n",
            "|        James|     Sales|  3000|    1|\n",
            "|     Gursheen|     Sales|  3000|    1|\n",
            "|        Rohit|     Sales|  4100|    1|\n",
            "|         Shah|     Sales|  4100|    2|\n",
            "|       Madhav|     Sales|  4600|    2|\n",
            "+-------------+----------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import cume_dist    \n",
        "df.withColumn(\"cume_dist\",cume_dist().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3LppUxuPfov",
        "outputId": "03ff15db-4b50-435a-eaa2-725003a35903"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------------------+\n",
            "|employee_name|department|salary|         cume_dist|\n",
            "+-------------+----------+------+------------------+\n",
            "|       Mitesh|   Finance|  3000|0.3333333333333333|\n",
            "|         Yash|   Finance|  3300|0.6666666666666666|\n",
            "|          Ben|   Finance|  3900|               1.0|\n",
            "|        Kumar| Marketing|  2000|               0.5|\n",
            "|       Pnadey| Marketing|  3000|               1.0|\n",
            "|        James|     Sales|  3000|               0.4|\n",
            "|     Gursheen|     Sales|  3000|               0.4|\n",
            "|        Rohit|     Sales|  4100|               0.8|\n",
            "|         Shah|     Sales|  4100|               0.8|\n",
            "|       Madhav|     Sales|  4600|               1.0|\n",
            "+-------------+----------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpecAgg  = Window.partitionBy(\"department\")\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import col,avg,sum,min,max,row_number \n",
        "df.withColumn(\"row\",row_number().over(windowSpec)) \\\n",
        "  .withColumn(\"avg\", avg(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"sum\", sum(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"min\", min(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"max\", max(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .where(col(\"row\")==1).select(\"department\",\"avg\",\"sum\",\"min\",\"max\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4ojoyOkPfvu",
        "outputId": "8ab270e4-e1a7-47aa-b0c2-964854e0a8cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+-----+----+----+\n",
            "|department|   avg|  sum| min| max|\n",
            "+----------+------+-----+----+----+\n",
            "|   Finance|3400.0|10200|3000|3900|\n",
            "| Marketing|2500.0| 5000|2000|3000|\n",
            "|     Sales|3760.0|18800|3000|4600|\n",
            "+----------+------+-----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kt_IKLsYPf3o"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_QwRk6aPf_k"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RxGH_QbYPgH2"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}